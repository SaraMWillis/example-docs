<!-- Custom HTML site displayed as the Home chapter -->

{% extends "main.html" %}
{% block tabs %}
{{ super() }}

<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="styles.css">


    
<!-- Main site header with buttons and descriptions -->
<section class="tx-container">
    <div class="md-grid md-typeset">
      <div class="tx-hero">
        <div class="tx-hero__content">
          <h1> UArizona HPC Services </h1>
          <p>The University of Arizona offers free high performance computing resources in the Research Data Center (RDC), a state-of-the-art facility that hosts large computer clusters. Scientific research relies upon such systems to analyze massive amounts of collected data.</p>
          <a href="running_jobs/batch_jobs/quick_start/" title="Quick Start" class="md-button md-button--primary">
            Quick Start
          </a>
          <a href="registration_and_access/account_creation/" title="Account Creation" class="md-button">
            Register for Access
          </a>
        </div>
      </div>
    </div>
</section>


<!-- Blue hero section with our mission statement -->
<div class="hero-section our-mission">
  <h2>Our Mission</h2>
  <div>
  <p>UArizona High Performance Computing (HPC) is an interdisciplinary research center focused on facilitating research and discoveries that advance science and technology. We deploy and operate advanced computing and data resources for the research activities of students, faculty, and staff at the University of Arizona. We also provide consulting, technical documentation, and training to support our users.
  <br><br>
  This site is divided into sections that describe the High Performance Computing (HPC) resources that are available, how to use them, and the rules for use.</p>
  </div>
</div>


<!-- News section. Contains cards with information on them -->
<center>
<h2> News </h2>

<div class="card-container">
    <div class="card">
        <img src="assets/images/home/apptainer.png" style="width:200px">
            <div class="container">
                <h4><b>Singularity Update</b></h4> 
                <p>Singularity has been renamed Apptainer as the project is brought into the Linux Foundation. An alias exists so that you can continue to invoke singularity. Local builds are now possible in many cases and remote builds with Sylabs are no longer supported</p> 
            </div>
    </div>
    <div class="card">
        <img src="assets/images/home/terminal.png" style="width:200px">
            <div class="container">
                <h4><b>Faster Interactive Sessions</b></h4> 
                <p>Are you frustrated waiting for slow interactive sessions to start? Try using the standard queue on ElGato. We have provisioned 44 nodes to only accept the standard queue to facilitate faster connections. To access a session</p> 
            </div>
    </div>
    <div class="card">
        <img src="assets/images/home/uarizona_rc.jpg" style="width:200px">
            <div class="container">
                <h4><b>UArizona at Supercomputing</b></h4> 
                <p>Our Research Technologies team represented the University of Arizona’s top tier research brand along with that of ASU and NAU at the Supercomputing Conference (SC23), this year held in Denver. <a href="https://it.arizona.edu/news/university-research-shines-supercomputing-conference" style="color: #AB0520;">Read the full story here</a>.</p> 
            </div>
    </div>
    <div class="card">
        <img src="assets/images/home/puma.jpg" style="width:200px">
            <div class="container">
                <h4><b>Puma News</b></h4> 
                <p>Last year we increased the standard allocation.  From the end of April 2022 the standard allocation of CPU hours is increased from 70,000 to 100,000. </p> 
            </div>
    </div>
</div>
</center>

<!-- Blue hero section with information on our resources -->
<!-- Main site header with buttons and descriptions -->
<section class="resources-tx-container">
    <div class="md-grid md-typeset">
      <div class="resources-tx-hero">
          <h1 align=right> Available Resources </h1>
          <h3 align=right> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" width="18" height="18"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d="M64 32C28.7 32 0 60.7 0 96v64c0 35.3 28.7 64 64 64H448c35.3 0 64-28.7 64-64V96c0-35.3-28.7-64-64-64H64zm280 72a24 24 0 1 1 0 48 24 24 0 1 1 0-48zm48 24a24 24 0 1 1 48 0 24 24 0 1 1 -48 0zM64 288c-35.3 0-64 28.7-64 64v64c0 35.3 28.7 64 64 64H448c35.3 0 64-28.7 64-64V352c0-35.3-28.7-64-64-64H64zm280 72a24 24 0 1 1 0 48 24 24 0 1 1 0-48zm56 24a24 24 0 1 1 48 0 24 24 0 1 1 -48 0z"/></svg> Compute</h3>
          <p align=right>UArizona HPC systems are available to all university faculty, staff, undergraduate and graduate students, postdocs, and designated campus colleagues (DCCs) at no cost. Researchers have access to <a href="../running_jobs/compute_resources/">compute resources on our three clusters</a> Puma, Ocelote, and ElGato located in our data center. Presently each research group is provided with a <a href="../running_jobs/allocations/">free standard monthly allocation</a> on each: 100,000 CPU-hours on Puma, 70,000 CPU-hours on Ocelote, and 7,000 CPU-hours on ElGato.</p>
          <center><hr width="40%"></center>
          <h3 align=left><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" width="18" height="18"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d="M448 80v48c0 44.2-100.3 80-224 80S0 172.2 0 128V80C0 35.8 100.3 0 224 0S448 35.8 448 80zM393.2 214.7c20.8-7.4 39.9-16.9 54.8-28.6V288c0 44.2-100.3 80-224 80S0 332.2 0 288V186.1c14.9 11.8 34 21.2 54.8 28.6C99.7 230.7 159.5 240 224 240s124.3-9.3 169.2-25.3zM0 346.1c14.9 11.8 34 21.2 54.8 28.6C99.7 390.7 159.5 400 224 400s124.3-9.3 169.2-25.3c20.8-7.4 39.9-16.9 54.8-28.6V432c0 44.2-100.3 80-224 80S0 476.2 0 432V346.1z"/></svg> Storage</h3>
          <p align=left>The University’s Research Data Center provides <a href="../storage_and_transfers/storage/hpc_storage/">data storage for active analysis</a> on the high-performance computers (HPCs). Your storage is mounted as a filesystem and all the clusters have access to the same filesystems. All users have access to a 50gb home directory, as well as a 500gb group allocation. Up to 20TB of additional temporary storage can be reserved at no cost. In addition to HPC storage, we also offer <a href="../storage_and_transfers/storage/rental_storage/">rental</a>, <a href="../storage_and_transfers/storage/tier2_storage/">archival</a>, and <a href="../storage_and_transfers/storage/rdas_storage/">desktop attached</a> storage for research groups.
              
          </p>
          <center><hr width="40%"></center>
          <h3 align=right><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" width="18" height="18"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d="M0 112.5V422.3c0 18 10.1 35 27 41.3c87 32.5 174 10.3 261-11.9c79.8-20.3 159.6-40.7 239.3-18.9c23 6.3 48.7-9.5 48.7-33.4V89.7c0-18-10.1-35-27-41.3C462 15.9 375 38.1 288 60.3C208.2 80.6 128.4 100.9 48.7 79.1C25.6 72.8 0 88.6 0 112.5zM288 352c-44.2 0-80-43-80-96s35.8-96 80-96s80 43 80 96s-35.8 96-80 96zM64 352c35.3 0 64 28.7 64 64H64V352zm64-208c0 35.3-28.7 64-64 64V144h64zM512 304v64H448c0-35.3 28.7-64 64-64zM448 96h64v64c-35.3 0-64-28.7-64-64z"/></svg> Funding Sources </h3>
          <p align=right>UArizona HPC systems are funded through the <a href="http://research.arizona.edu/">UArizona Research Office (RII)</a> and CIO/UITS (Chief Information Officer, and University Information Technology Services). Staff is funded to administer the systems and provide <a href="support_and_training/consulting_services/">consulting services</a> (no charge) for all researchers.</p>
          <center><hr width="40%"></center>
          <h3 align=left><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" width="18" height="18"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path d="M336 352c97.2 0 176-78.8 176-176S433.2 0 336 0S160 78.8 160 176c0 18.7 2.9 36.8 8.3 53.7L7 391c-4.5 4.5-7 10.6-7 17v80c0 13.3 10.7 24 24 24h80c13.3 0 24-10.7 24-24V448h40c13.3 0 24-10.7 24-24V384h40c6.4 0 12.5-2.5 17-7l33.3-33.3c16.9 5.4 35 8.3 53.7 8.3zM376 96a40 40 0 1 1 0 80 40 40 0 1 1 0-80z"/></svg> Regulated Research</h3>
          <p align=left>These resources specifically do not support Regulated Research, which might be ITAR, HIPAA or CUI (Controlled Unclassified Information). For more information on services that can support regulated research, see: <a href="https://uarizona.service-now.com/sp?id=sc_cat_item&sys_id=32755b2d1bcb28107947edf1604bcbd1">HIPAA support services</a> and <a href="https://uarizona.service-now.com/sp?id=sc_cat_item&sys_id=da15df6d1bcb28107947edf1604bcbeb">CUI support services</a>.</p>

      </div>
    </div>
</section>


<!-- Testing a section for calendar information -->
<div class="hero-section quick-links">
    <h2>Calendar</h2>
    <div class="card" style="max-width:70%">
        <div class="container">
            <h4>Intro to HPC Workshop</h4>
            <p>Date: October 27, 2024 @ 10:00-12:00pm (MST)<br>Location: Online<br>Registration: (link)</p>
        </div>
    </div>
    <div class="card" style="max-width:70%">
        <div class="container">
            <h4>Intro to Fooing and also Barring</h4>
            <p>Date: October 28, 2024 @ 11:00-1:00pm (MST)<br>Location: Baz<br>Registration: (link)</p>
        </div>
    </div>
</div>

<!-- Split section, picture of research on the left, description on the right -->

<div class="research-container">
    <div class="image">
        <img src="assets/images/home/HypersonicTravel.jpg" style="width:100%;">
    </div>
        <div class="text">
        <h2>Highlighted Research</h2>
        <h3>Faster Speeds Need Faster Computation</h3>
        <h4>Hypersonic Travel</h4>
        <p> Professors Christoph Hader, Hermann Fasel, and their team are exploring the use of our GPUs to optimize Navier-Stokes codes for simulating the flow field around hypersonic vehicles traveling at size times the speed of sound (Mach 6) or more. <br><br>
        In the image to the right, instantaneous flow structures obtained from a DNS for a flared cone at Mach 6 are visualized using the Q-isocontours colored with instantaneous temperature disturbance values. The small scales towards the end of the computational domain indicate the regions where the boundary layer is turbulent. </p>
        </div>
</div>



<!-- A slideshow that shows our clusters with information about each -->
<center><h2>Our Clusters</h2></center>
 <!-- Slideshow container -->
<div class="slideshow-container">

  <!-- Full-width images with number and caption text -->
  <div class="mySlides fade">
    <div class="numbertext">1 / 4</div>
    <img src="assets/images/home/puma.png" style="width:100%">
    <div class="text-box">
      <div class="text"><h3>Puma</h3><br>
      Implemented in the middle of 2020, Puma is the biggest cat yet. Similar to Ocelote, it has standard CPU nodes (with 94 cores and 512 GB of memory per node), GPU nodes (with Nvidia V100) and two high-memory nodes (3 TB). Local scratch storage increased to ~1.4 TB. Puma runs on CentOS 7.<br>
      As is the case for our other supercomputers, we use the RFP process to get the best value for our financial resources, that meet our technical requirements.  This time Penguin Computing one with AMD processors. This is tremendously valuable as each node comes with:<br>
        &ensp;- Two AMD Zen2 48 core processors<br>
        &ensp;- 512GB RAM<br>
        &ensp;- 25Gb path to storage<br>
        &ensp;- 25Gb path to other nodes for MPI<br>
        &ensp;- 2TB internal NVME disk (largely available as /tmp)<br>
        &ensp;- Qumulo all flash storage array for shared filesystems<br>
        &ensp;- Two large memory nodes with 3TB memory and the same processors and memory as the other nodes<br>
        &ensp;- Six nodes with four Nvidia V100S GPU's each <br>
    </div>
    </div>
  </div>

  <div class="mySlides fade">
    <div class="numbertext">2 / 4</div>
    <img src="assets/images/home/cables.png" style="width:100%">
    <div class="text-box">
      <div class="text"><h3>Ocelote</h3><br>
      Ocelote arrived in 2016. Lenovo's Nextscale M5 technology was the winner of the RFP mainly on price, performance and meeting our specific requirements. Ocelote has one large memory node with 2TB of memory and 46 nodes with Nvidia P100 GPUs for GPU-accelerated workflows. This cluster is actually the next generation of the IBM cluster we call ElGato. Lenovo purchased IBM's Intel server line in 2015.<br>
      In 2021, Ocelote's operating system was upgraded from CentOS6 to CentOS7 and was configured to use SLURM, like Puma. It will continue until it is either too expensive to maintain or it is replaced by something else.<br>
      &ensp;- Intel Haswell V3 28 core processors<br>
      &ensp;- 192GB RAM per node<br>
      &ensp;- FDR infiniband for fast MPI interconnect<br>
      &ensp;- Qumulo all flash storage array (all HPC storage is integrated into one array)<br>
      &ensp;- One large memory node with 2TB RAM,  Intel Ivy Bridge V2 48 cores<br>
      &ensp;- 46 nodes with Nvidia P100 GPU's<br>

    </div>
    </div>
  </div>

  <div class="mySlides fade">
    <div class="numbertext">3 / 4</div>
    <img src="assets/images/home/HPC_0.png" style="width:100%">
    <div class="text-box">
      <div class="text"><h3>ElGato</h3><br>
    Implemented at the start of 2014, ElGato has been reprovisioned with CentOS 7 and new compilers and libraries. From July 2021 it has been using Slurm for job submission. ElGato is our smallest cluster with 130 standard nodes each with 16 CPUs. Purchased by an NSF MRI grant by researchers in Astronomy and SISTA.
      </div>
    </div>
    </div>

  <div class="mySlides fade">
    <div class="numbertext">4 / 4</div>
    <iframe width="1000" height="500" src="https://www.youtube.com/embed/JOJ8RO4tLcc" frameborder="0" allowfullscreen></iframe>

    </div>


  <!-- Next and previous buttons -->
  <a class="prev" onclick="plusSlides(-1)">&#10094;</a>
  <a class="next" onclick="plusSlides(1)">&#10095;</a>
</div>
<br>

<!-- The dots/circles -->
<div style="text-align:center">
  <span class="dot" onclick="currentSlide(1)"></span>
  <span class="dot" onclick="currentSlide(2)"></span>
  <span class="dot" onclick="currentSlide(3)"></span>
  <span class="dot" onclick="currentSlide(4)"></span>
</div> 

<script src="assets/javascripts/slideshow.js"></script>


<!-- Line to divide the footer -->
<div class="top-hr">
    <div class="hr">
    </div>
</div>



<!-- Footer with land acknowledgement -->
<footer>

<div class="md-footer-land-acknowledgement">
    <center>
    <i>
    We respectfully acknowledge the University of Arizona is on the land and territories of Indigenous peoples. Today, Arizona is home to 22 federally recognized tribes, with Tucson being home to the O'odham and the Yaqui. Committed to diversity and inclusion, the University strives to build sustainable relationships with sovereign Native Nations and Indigenous communities through education offerings, partnerships, and community service.
    </i>
    <center>
</div>


</footer>

{% endblock %}
{% block content %}{% endblock %}
{% block footer %}
<footer class="md-footer">
    <div class="md-footer-meta md-typeset">
        <div class="md-footer-meta__inner md-grid">
            <!-- Copyright and theme information -->
            <div class="md-footer-copyright">
                {% if config.copyright %}
                <div class="md-footer-copyright__highlight">
                    {{ config.copyright }}
                </div>
                {% endif %}
                University of Arizona Research Computing
            </div>
            {% block social %}
            {% include "partials/social.html" %}
            {% endblock %}
        </div>
    </div>
</footer>
{% endblock %}